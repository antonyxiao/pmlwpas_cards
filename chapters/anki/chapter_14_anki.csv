Type	Front	Back	Tags
Basic	What is a "convolution"?	Sliding filter operation on input	chapter14::prerequisites
Basic	What is a "kernel/filter"?	Small weight matrix for convolution	chapter14::prerequisites
Basic	What is a "feature map"?	Output of convolution layer	chapter14::prerequisites
Basic	What is "pooling"?	Downsampling operation	chapter14::prerequisites
Basic	What is a "channel"?	Depth dimension (e.g., RGB = 3)	chapter14::prerequisites
Basic	What inspired CNNs?	Visual cortex neuron structure	chapter14::cnn-fundamentals
Basic	Who proposed first CNN (1989)?	Yann LeCun	chapter14::cnn-fundamentals
Basic	What is a feature hierarchy?	Low-level features → high-level features	chapter14::feature-hierarchy
Basic	What is local receptive field?	Patch of pixels a neuron connects to	chapter14::receptive-field
Basic	Why are CNNs parameter-efficient?	Sparse connectivity + weight sharing	chapter14::convolution
Basic	Typical CNN architecture pattern?	Conv + Pool layers → Fully connected	chapter14::cnn-architecture
Basic	What is zero-padding?	Adding zeros around input border	chapter14::padding
Basic	What is "same" padding?	Output size = input size	chapter14::padding
Basic	What is "valid" padding?	No padding (p=0)	chapter14::padding
Basic	What is stride?	Filter step size	chapter14::convolution
Cloze	CNN output size: o = {{c1::floor((n + 2p - m)/s) + 1}}		chapter14::output-size
Basic	Convolution vs cross-correlation?	DL uses cross-correlation, calls it convolution	chapter14::convolution
Basic	What is max-pooling?	Take maximum from neighborhood	chapter14::pooling
Basic	What is mean-pooling?	Take average of neighborhood	chapter14::pooling
Basic	Two pooling advantages?	Local invariance, reduced computation	chapter14::pooling
Basic	Do pooling layers have parameters?	No	chapter14::pooling
Basic	Alternative to pooling?	Strided convolution	chapter14::pooling
Cloze	RGB images have {{c1::3}} channels		chapter14::channels
Basic	Conv with multiple channels?	Convolve each, sum results	chapter14::channels
Basic	Conv kernel tensor dimensions?	4D: width × height × C_in × C_out	chapter14::feature-maps
Basic	What is dropout?	Randomly zero neurons during training	chapter14::dropout
Cloze	Common dropout probability: {{c1::0.5}}		chapter14::dropout
Basic	Dropout train vs inference?	Train: drop units; Inference: all units, scaled	chapter14::dropout
Basic	Loss for binary with probabilities?	nn.BCELoss()	chapter14::loss-functions
Basic	Loss for binary with logits?	nn.BCEWithLogitsLoss()	chapter14::loss-functions
Basic	Loss for multiclass with logits?	nn.CrossEntropyLoss()	chapter14::loss-functions
Basic	What is data augmentation?	Modifying training images to reduce overfitting	chapter14::data-augmentation
Basic	Common augmentations?	Random crop, flip, contrast adjust	chapter14::data-augmentation
Basic	Apply augmentation to test set?	No, only training	chapter14::data-augmentation
Basic	What is global average pooling?	Pool size = feature map size → 1×1 output	chapter14::global-pooling
Basic	Global pooling advantage?	Drastically reduces parameters	chapter14::global-pooling
Basic	Train vs eval mode switch?	model.train() vs model.eval()	chapter14::pytorch-training
Cloze	PyTorch image format NCHW: N={{c1::batch}}, C={{c2::channels}}, H={{c3::height}}, W={{c4::width}}		chapter14::pytorch-cnn
Cloze	Same padding for 3×3 kernel, stride 1: padding={{c1::1}}		chapter14::padding
Cloze	Common kernel sizes: {{c1::1×1}}, {{c2::3×3}}, {{c3::5×5}}		chapter14::convolution
Basic	Write code to create Conv2d.	nn.Conv2d(in_channels, out_channels, kernel_size)	chapter14::code
Basic	Write code for Conv2d with padding.	nn.Conv2d(3, 32, kernel_size=3, padding=1)	chapter14::code
Basic	Write code for MaxPool2d.	nn.MaxPool2d(kernel_size=2, stride=2)	chapter14::code
Basic	Write code for AvgPool2d.	nn.AvgPool2d(kernel_size=2)	chapter14::code
Basic	Write code for Dropout.	nn.Dropout(p=0.5)	chapter14::code
Basic	Write code for random horizontal flip.	transforms.RandomHorizontalFlip()	chapter14::code
Basic	Write code for random crop.	transforms.RandomCrop(size)	chapter14::code
Basic	Write code to compose transforms.	transforms.Compose([transforms.ToTensor(), transforms.Normalize(...)])	chapter14::code
Basic	Write code to switch to train mode.	model.train()	chapter14::code
Basic	Write code to switch to eval mode.	model.eval()	chapter14::code
Basic	Write code for global average pooling.	nn.AdaptiveAvgPool2d(1)	chapter14::code
Basic	Write code for Flatten layer.	nn.Flatten()	chapter14::code
