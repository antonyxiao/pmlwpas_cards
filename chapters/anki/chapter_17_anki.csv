Type	Front	Back	Tags
Basic	What is "generative model"?	Model that can generate new data	chapter17::prerequisites
Basic	What is "latent space"?	Compressed representation space	chapter17::prerequisites
Basic	What is "discriminator"?	Network that classifies real vs fake	chapter17::prerequisites
Basic	What is "generator"?	Network that creates fake samples	chapter17::prerequisites
Basic	What is a GAN?	Generative Adversarial Network	chapter17::gan-framework
Basic	Who proposed GANs (2014)?	Ian Goodfellow	chapter17::gan-framework
Basic	Two GAN components?	Generator and Discriminator	chapter17::gan-framework
Basic	Generator's goal?	Create fakes that fool discriminator	chapter17::generator
Basic	Discriminator's goal?	Distinguish real from fake	chapter17::discriminator
Basic	Generator tries to?	Minimize D's ability to distinguish	chapter17::gan-framework
Basic	Discriminator tries to?	Maximize classification accuracy	chapter17::gan-framework
Basic	GAN loss function?	Binary cross-entropy	chapter17::loss-functions
Basic	Why alternate training?	Simultaneous optimization is hard	chapter17::training-procedure
Basic	What is saturation in GANs?	Vanishing gradients when D is confident	chapter17::training-stability
Basic	Solution to saturation?	Maximize log(D(G(z))) instead of min log(1-D(G(z)))	chapter17::training-stability
Basic	What is an autoencoder?	Encoder + decoder for reconstruction	chapter17::autoencoders
Cloze	Autoencoder: z = {{c1::encoder(x)}}, xÌ‚ = {{c2::decoder(z)}}		chapter17::autoencoders
Basic	What is the latent vector z?	Compressed representation	chapter17::autoencoders
Basic	What is a VAE?	Variational Autoencoder	chapter17::vae
Basic	VAE vs standard autoencoder?	VAE outputs distribution, not fixed vector	chapter17::vae
Basic	What is mode collapse?	Generator produces limited variety	chapter17::mode-collapse
Basic	What is DCGAN?	Deep Convolutional GAN	chapter17::dcgan
Basic	DCGAN generator uses?	Transposed convolutions	chapter17::dcgan
Basic	What is transposed convolution?	Insert zeros, then convolve (upsampling)	chapter17::transposed-convolution
Basic	Why leaky ReLU in GANs?	Gradients for negative inputs	chapter17::leaky-relu
Basic	What is batch normalization?	Normalize using batch statistics	chapter17::batch-normalization
Basic	With BatchNorm, set bias to?	False in preceding layer	chapter17::batch-normalization
Basic	What is WGAN?	Wasserstein GAN	chapter17::wgan
Basic	WGAN uses what distance?	Earth Mover's (Wasserstein)	chapter17::wgan
Basic	Why Wasserstein over JS divergence?	Meaningful gradients when distributions don't overlap	chapter17::wgan
Basic	WGAN discriminator called?	Critic (outputs scores, not probabilities)	chapter17::wgan
Basic	What is WGAN-GP?	WGAN with gradient penalty	chapter17::wgan-gp
Cloze	WGAN-GP lambda typically {{c1::10}}		chapter17::wgan-gp
Basic	What is conditional GAN?	GAN conditioned on labels	chapter17::gan-variants
Basic	What is CycleGAN?	Image-to-image with unpaired data	chapter17::gan-variants
Basic	GAN evaluation metrics?	Inception Score, FID	chapter17::evaluation
Write code for transposed conv.	nn.ConvTranspose2d(in_ch, out_ch, kernel_size, stride, padding)	chapter17::code
Basic	Write code for LeakyReLU.	nn.LeakyReLU(0.2)	chapter17::code
Basic	Write code for BatchNorm2d.	nn.BatchNorm2d(num_features)	chapter17::code
Basic	Write code for Conv without bias.	nn.Conv2d(in_ch, out_ch, kernel_size, bias=False)	chapter17::code
Basic	Write code for BCEWithLogitsLoss.	nn.BCEWithLogitsLoss()	chapter17::code
Basic	Write code to sample from normal.	z = torch.randn(batch_size, latent_dim)	chapter17::code
