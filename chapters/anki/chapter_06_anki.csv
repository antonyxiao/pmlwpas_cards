Type	Front	Back	Tags
Basic	What is a "pipeline" in ML?	Chain of transformations + final estimator	chapter06::prerequisites
Basic	What is "cross-validation"?	Evaluating model on multiple data splits	chapter06::prerequisites
Basic	What is a "fold" in CV?	One subset of the data	chapter06::prerequisites
Basic	What is a "confusion matrix"?	Table of TP, TN, FP, FN counts	chapter06::prerequisites
Basic	What is "ROC"?	Receiver Operating Characteristic	chapter06::prerequisites
Basic	What is "AUC"?	Area Under the Curve	chapter06::prerequisites
Basic	What is "class imbalance"?	One class has far more samples	chapter06::prerequisites
Basic	What does Pipeline.fit() do?	Runs fit_transform on all steps, fit on final	chapter06::pipelines
Basic	What does Pipeline.predict() do?	Runs transform on all steps, predict on final	chapter06::pipelines
Basic	What is the holdout method?	Single train/test split	chapter06::cross-validation
Basic	Why not reuse test set for tuning?	Causes indirect overfitting	chapter06::cross-validation
Basic	What is training set for?	Fitting models	chapter06::cross-validation
Basic	What is validation set for?	Tuning hyperparameters	chapter06::cross-validation
Basic	What is test set for?	Final unbiased evaluation	chapter06::cross-validation
Cloze	In k-fold CV, data splits into {{c1::k}} folds		chapter06::cross-validation
Basic	How many folds used for training in k-fold?	k-1	chapter06::cross-validation
Basic	How many folds used for testing in k-fold?	1	chapter06::cross-validation
Basic	What is stratified k-fold?	Preserves class proportions in folds	chapter06::cross-validation
Basic	Good default value for k?	10	chapter06::cross-validation
Basic	When increase k?	Small datasets	chapter06::cross-validation
Basic	When decrease k?	Large datasets (for speed)	chapter06::cross-validation
Basic	What is LOOCV?	Leave-One-Out CV (k = n samples)	chapter06::cross-validation
Basic	What do learning curves show?	Accuracy vs training set size	chapter06::learning-curves
Basic	High bias sign in learning curve?	Both curves converge low	chapter06::learning-curves
Basic	High variance sign in learning curve?	Large gap between curves	chapter06::learning-curves
Basic	How to fix high bias?	More complex model, less regularization	chapter06::learning-curves
Basic	How to fix high variance?	More data, more regularization	chapter06::learning-curves
Basic	What do validation curves show?	Accuracy vs hyperparameter value	chapter06::validation-curves
Basic	Parameters vs hyperparameters?	Parameters learned; hyperparameters set manually	chapter06::hyperparameter-tuning
Basic	What is grid search?	Try all hyperparameter combinations	chapter06::hyperparameter-tuning
Basic	What is randomized search?	Sample random hyperparameter combinations	chapter06::hyperparameter-tuning
Basic	Advantage of randomized search?	Explores wider space, faster	chapter06::hyperparameter-tuning
Basic	What is successive halving?	Eliminate bottom 50% iteratively	chapter06::hyperparameter-tuning
Basic	What is nested CV?	CV for model selection + CV for evaluation	chapter06::hyperparameter-tuning
Cloze	Confusion matrix: {{c1::TP}}, {{c2::TN}}, {{c3::FP}}, {{c4::FN}}		chapter06::metrics
Cloze	Accuracy = {{c1::(TP + TN) / Total}}		chapter06::metrics
Cloze	Precision = {{c1::TP / (TP + FP)}}		chapter06::metrics
Cloze	Recall = {{c1::TP / (TP + FN)}}		chapter06::metrics
Cloze	F1 = {{c1::2 * Precision * Recall / (Precision + Recall)}}		chapter06::metrics
Cloze	FPR = {{c1::FP / (FP + TN)}}		chapter06::metrics
Cloze	TPR = {{c1::TP / (TP + FN)}}		chapter06::metrics
Basic	When prioritize recall?	False negatives are costly	chapter06::metrics
Basic	Example: prioritize recall?	Disease screening	chapter06::metrics
Basic	When prioritize precision?	False positives are costly	chapter06::metrics
Basic	Example: prioritize precision?	Spam filtering	chapter06::metrics
Basic	Why MCC better than F1?	Uses all four confusion matrix values	chapter06::metrics
Basic	What does ROC curve plot?	TPR vs FPR at different thresholds	chapter06::metrics
Basic	What does ROC diagonal mean?	Random guessing	chapter06::metrics
Basic	What is ROC AUC range?	0 to 1 (higher is better)	chapter06::metrics
Basic	What is micro-averaging?	Aggregate TP/TN/FP/FN across classes	chapter06::metrics
Basic	What is macro-averaging?	Average metric across classes	chapter06::metrics
Basic	Three ways to handle class imbalance?	Upsample minority, downsample majority, SMOTE	chapter06::class-imbalance
Basic	What is SMOTE?	Generate synthetic minority samples	chapter06::class-imbalance
Basic	How SMOTE generates samples?	Interpolate between existing minority samples	chapter06::class-imbalance
Basic	sklearn parameter for imbalance?	class_weight='balanced'	chapter06::class-imbalance
Basic	Why accuracy misleading for imbalance?	Predicting majority class gives high accuracy	chapter06::class-imbalance
Basic	Better metrics for imbalanced data?	Precision, recall, F1, MCC, ROC AUC	chapter06::class-imbalance
Basic	Write code to create Pipeline.	from sklearn.pipeline import Pipeline; pipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression())])	chapter06::code
Basic	Write code for cross_val_score.	from sklearn.model_selection import cross_val_score; scores = cross_val_score(clf, X, y, cv=10)	chapter06::code
Basic	Write code to get mean CV score.	scores.mean()	chapter06::code
Basic	Write code to create GridSearchCV.	from sklearn.model_selection import GridSearchCV; gs = GridSearchCV(clf, param_grid, cv=5)	chapter06::code
Basic	How to access best params after grid search?	gs.best_params_	chapter06::code
Basic	How to access best score after grid search?	gs.best_score_	chapter06::code
Basic	How to access best model after grid search?	gs.best_estimator_	chapter06::code
Basic	Write code to create confusion matrix.	from sklearn.metrics import confusion_matrix; cm = confusion_matrix(y_true, y_pred)	chapter06::code
Basic	Write code for classification report.	from sklearn.metrics import classification_report; print(classification_report(y_true, y_pred))	chapter06::code
Basic	Write code to compute ROC AUC.	from sklearn.metrics import roc_auc_score; roc_auc_score(y_true, y_proba)	chapter06::code
Basic	Write code to plot ROC curve.	from sklearn.metrics import RocCurveDisplay; RocCurveDisplay.from_estimator(clf, X_test, y_test)	chapter06::code
Basic	Write code for stratified k-fold.	from sklearn.model_selection import StratifiedKFold; skf = StratifiedKFold(n_splits=10)	chapter06::code
Basic	Write code for learning curve.	from sklearn.model_selection import learning_curve	chapter06::code
Basic	Pipeline param_grid format?	'stepname__param': [values]	chapter06::code
Basic	Write code for RandomizedSearchCV.	from sklearn.model_selection import RandomizedSearchCV; rs = RandomizedSearchCV(clf, param_dist, n_iter=100)	chapter06::code
