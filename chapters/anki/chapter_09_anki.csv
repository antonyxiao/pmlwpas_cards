Type	Front	Back	Tags
Basic	What is "regression" in ML?	Predicting continuous values	chapter09::prerequisites
Basic	What is a "residual"?	Difference between predicted and actual	chapter09::prerequisites
Basic	What is "correlation"?	Linear relationship strength between variables	chapter09::prerequisites
Basic	What is OLS?	Ordinary Least Squares	chapter09::prerequisites
Basic	What is "heteroscedasticity"?	Non-constant variance of residuals	chapter09::prerequisites
Basic	What is linear regression's goal?	Model relationship with continuous target	chapter09::linear-regression
Cloze	Simple linear regression: y = {{c1::wx + b}}		chapter09::linear-regression
Cloze	Multiple linear regression: y = {{c1::w₁x₁ + w₂x₂ + ... + b}}		chapter09::linear-regression
Basic	What are residuals in regression?	Vertical distances from line to actual values	chapter09::linear-regression
Basic	What does OLS minimize?	Sum of squared residuals	chapter09::ols
Cloze	MSE = {{c1::(1/n)Σ(y - ŷ)²}}		chapter09::metrics
Basic	OLS relationship to Adaline?	OLS is Adaline without threshold function	chapter09::ols
Cloze	Closed-form OLS solution: w = {{c1::(XᵀX)⁻¹Xᵀy}}		chapter09::ols
Basic	Closed-form solution disadvantage?	Expensive matrix inversion for large data	chapter09::ols
Basic	Why standardize for gradient descent?	Faster, more reliable convergence	chapter09::gradient-descent
Basic	What is RANSAC for?	Regression robust to outliers	chapter09::ransac
Basic	What is a residual plot?	Residuals vs predicted values	chapter09::diagnostics
Basic	Good residual plot looks like?	Random scatter around zero	chapter09::diagnostics
Basic	Pattern in residual plot means?	Model missing some information	chapter09::diagnostics
Cloze	MAE = {{c1::(1/n)Σ|y - ŷ|}}		chapter09::metrics
Basic	MAE vs MSE advantage?	MAE in original units	chapter09::metrics
Cloze	R² = 1 - {{c1::SSE/SST}}		chapter09::metrics
Cloze	SSE = {{c1::Σ(y - ŷ)²}}		chapter09::metrics
Cloze	SST = {{c1::Σ(y - mean(y))²}}		chapter09::metrics
Basic	What does R² = 1 mean?	Perfect fit (MSE = 0)	chapter09::metrics
Basic	Can R² be negative?	Yes, on test data	chapter09::metrics
Basic	Negative R² means?	Worse than predicting mean	chapter09::metrics
Basic	Why prefer R² over MSE?	Standardized and scale-independent	chapter09::metrics
Basic	What is Ridge regression?	Linear regression + L2 penalty	chapter09::regularization
Basic	What is LASSO?	Linear regression + L1 penalty	chapter09::regularization
Basic	Why does LASSO create sparsity?	L1 constraint has corners on axes	chapter09::regularization
Basic	LASSO limitation when m > n?	Selects at most n features	chapter09::regularization
Basic	What is Elastic Net?	L1 + L2 penalties combined	chapter09::regularization
Basic	Elastic Net advantage over LASSO?	Can select more than n features	chapter09::regularization
Basic	What does regularization do to weights?	Shrinks toward zero	chapter09::regularization
Basic	sklearn regularization parameter name?	alpha	chapter09::regularization
Basic	Is bias term regularized?	No	chapter09::regularization
Cloze	Polynomial regression: y = w₁x + w₂x² + ... + {{c1::wdxᵈ}} + b		chapter09::polynomial-regression
Basic	Is polynomial regression linear?	Yes (coefficients are linear)	chapter09::polynomial-regression
Basic	High-degree polynomial risk?	Overfitting	chapter09::polynomial-regression
Basic	Decision tree regression impurity measure?	MSE (within-node variance)	chapter09::decision-trees
Basic	Decision tree regression prediction?	Mean of leaf node examples	chapter09::decision-trees
Basic	Decision tree regression limitation?	Step-wise constant predictions	chapter09::decision-trees
Cloze	Pearson r ranges from {{c1::-1}} to {{c2::+1}}		chapter09::correlation
Cloze	Pearson r = {{c1::cov(x,y) / (σx × σy)}}		chapter09::correlation
Basic	What is a correlation matrix?	Pairwise correlations between features	chapter09::correlation
Basic	High train R², low test R² indicates?	Overfitting	chapter09::overfitting
Basic	What does slope (w) represent?	Change in y per unit change in x	chapter09::linear-regression
Basic	What does intercept (b) represent?	y when x = 0	chapter09::linear-regression
Basic	Write code for LinearRegression.	from sklearn.linear_model import LinearRegression; lr = LinearRegression()	chapter09::code
Basic	Write code to fit linear regression.	lr.fit(X_train, y_train)	chapter09::code
Basic	Write code to get predictions.	y_pred = lr.predict(X_test)	chapter09::code
Basic	How to access coefficients?	lr.coef_	chapter09::code
Basic	How to access intercept?	lr.intercept_	chapter09::code
Basic	Write code to compute MSE.	from sklearn.metrics import mean_squared_error; mse = mean_squared_error(y_true, y_pred)	chapter09::code
Basic	Write code to compute R².	from sklearn.metrics import r2_score; r2 = r2_score(y_true, y_pred)	chapter09::code
Basic	Write code for Ridge regression.	from sklearn.linear_model import Ridge; ridge = Ridge(alpha=1.0)	chapter09::code
Basic	Write code for LASSO.	from sklearn.linear_model import Lasso; lasso = Lasso(alpha=1.0)	chapter09::code
Basic	Write code for Elastic Net.	from sklearn.linear_model import ElasticNet; en = ElasticNet(alpha=1.0, l1_ratio=0.5)	chapter09::code
Basic	Write code for polynomial features.	from sklearn.preprocessing import PolynomialFeatures; poly = PolynomialFeatures(degree=2)	chapter09::code
Basic	Write code for RANSAC.	from sklearn.linear_model import RANSACRegressor; ransac = RANSACRegressor()	chapter09::code
Basic	Write code for DecisionTreeRegressor.	from sklearn.tree import DecisionTreeRegressor; tree = DecisionTreeRegressor(max_depth=3)	chapter09::code
Basic	Write code for RandomForestRegressor.	from sklearn.ensemble import RandomForestRegressor; rf = RandomForestRegressor(n_estimators=100)	chapter09::code
